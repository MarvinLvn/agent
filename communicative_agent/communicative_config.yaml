model:
  direct_model:
    nb_derivatives: 0
    hidden_layers: [256, 256, 256, 256]
    activation: relu
    batch_norm: true
    dropout_p: 0.25
  inverse_model:
    num_layers: 2
    hidden_size: 32
    dropout_p: 0.25
    bidirectional: False
  sound_quantizer:
    hidden_dims: [256, 256, 256, 256]
    activation: relu
    dropout_p: 0.25
    batch_norm: true
    frame_padding: 2
    num_embeddings: 64
    embedding_dim: 32
    commitment_cost: .25
    use_speaker_id: true
  art_quantizer:
    hidden_dims: [256, 256, 256, 256]
    activation: relu
    dropout_p: 0.25
    batch_norm: true
    frame_padding: 2
    num_embeddings: 64
    embedding_dim: 32
    commitment_cost: .25
    use_speaker_id: true
synthesizer:
  name: dn=pb2007-nd=2-hl=256,256,256,256-in=ema-out=cepstrum-0
dataset:
  names: [pb2007]
  sound_type: cepstrum
  datasplits_size: [64, 16, 20] # train/validation/test in percentage
  batch_size: 8
  num_workers: 6
  shuffle_between_epochs: true
training:
  learning_rate: 0.001
  max_epochs: 500
  patience: 25
  jerk_loss_weight: 1
